{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BlazeFace_.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOSg8/8TJDLT1TbNrDAPqT2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/subham913/BlazeFace_/blob/master/BlazeFace_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2YX-vzctN24k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NKuUaRJNUuKu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def SingleBlazeBlock(x, filter_size, kernel_size = 5, strides = 1):\n",
        "  _x = tf.keras.layers.SeparableConv2D(filters = filter_size, kernel_size=kernel_size, strides = strides, padding = 'same', use_bias=False)(x)\n",
        "  _x = tf.keras.layers.BatchNormalization()(_x)\n",
        "  channel_pad = _x.shape[-1] - x.shape[-1] #######Channel padding for residual connections\n",
        "  if(strides==2):\n",
        "    x = tf.keras.layers.MaxPooling2D()(x)\n",
        "    if(channel_pad):\n",
        "      # x = tf.keras.backend.concatenate([x,tf.zeros((x.shape[0],x.shape[1],x.shape[2],channel_pad),dtype = x.dtype)],axis=-1)\n",
        "      x = tf.keras.backend.concatenate([x,tf.zeros_like(x)],axis=-1) \n",
        "  \n",
        "  x_out = tf.keras.layers.Add()([_x,x])\n",
        "  x_out = tf.keras.layers.Activation(\"relu\")(x_out)\n",
        "  return x_out\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W981b3JigMGe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def DoubleBlazeBlock(x, filter1_size, filter2_size, kernel_size = 5, strides = 1):\n",
        "  \n",
        "  _x1 = tf.keras.layers.SeparableConv2D(filters = filter1_size, kernel_size=kernel_size, strides= strides, padding = 'same', use_bias=False)(x)\n",
        "  _x1 = tf.keras.layers.BatchNormalization()(_x1)\n",
        "  _x1 = tf.keras.layers.Activation(\"relu\")(_x1)\n",
        "\n",
        "  _x2 = tf.keras.layers.SeparableConv2D(filters = filter2_size, kernel_size=kernel_size, strides = 1, padding = 'same', use_bias=False)(_x1)\n",
        "  _x2 = tf.keras.layers.BatchNormalization()(_x2)\n",
        "\n",
        "  channel_pad = _x2.shape[-1] - x.shape[-1]\n",
        "  if(strides==2):\n",
        "    x = tf.keras.layers.MaxPooling2D()(x)\n",
        "    if(channel_pad):\n",
        "      # x = tf.keras.backend.concatenate([x,tf.zeros((x.shape[0],x.shape[1],x.shape[2],channel_pad),dtype = x.dtype)],axis=-1)\n",
        "      x = tf.keras.backend.concatenate([x,tf.zeros_like(x)],axis=-1)\n",
        "  x_out = tf.keras.layers.Add()([_x2,x])\n",
        "  x_out = tf.keras.layers.Activation(\"relu\")(x_out)\n",
        "  return x_out\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SMROBVweSFRo",
        "colab_type": "text"
      },
      "source": [
        "#Test SigleBlazeBlock"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wHvC9fJERTFF",
        "colab_type": "code",
        "outputId": "315fa5fb-106c-4278-aa5d-a4da6b0e00bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import numpy as np\n",
        "# m  = tf.keras.layers.SeparableConv2D(filters = 24, kernel_size=5, strides = 2, padding = 'same')\n",
        "a = tf.convert_to_tensor(np.random.randn(3,64,64,24),dtype = tf.float32)\n",
        "out = SingleBlazeBlock(a, 48, strides=2)\n",
        "print(out.shape)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3, 32, 32, 48)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i4s97K4ASNDq",
        "colab_type": "text"
      },
      "source": [
        "# Test DoubleBlazeBlock"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e0GIq8lkSU7q",
        "colab_type": "code",
        "outputId": "b097d29a-0cfc-4e3c-a0a2-ccb7669ae06c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import numpy as np\n",
        "# m  = tf.keras.layers.SeparableConv2D(filters = 24, kernel_size=5, strides = 2, padding = 'same')\n",
        "a = tf.convert_to_tensor(np.random.randn(3,32,32,48),dtype = tf.float32)\n",
        "out = DoubleBlazeBlock(a, 24, 48, strides=1)\n",
        "print(out.shape)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3, 32, 32, 48)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9lbj21D6GTUS",
        "colab_type": "text"
      },
      "source": [
        "#Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AypFHCWRdJvt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def network():\n",
        "  inputs = tf.keras.layers.Input(shape=(128,128,3))\n",
        "  x = tf.keras.layers.Conv2D(kernel_size = 5, filters = 24, strides = 2, padding = 'same')(inputs) ## bx64x64x24\n",
        "  \n",
        "  x = SingleBlazeBlock(x, 24) ## bx64x64x24\n",
        "  x = SingleBlazeBlock(x, 24) ## bx64x64x24\n",
        "  x = SingleBlazeBlock(x, 48, strides = 2) ## bx32x32x48\n",
        "  x = SingleBlazeBlock(x, 48) ## bx32x32x48\n",
        "  x = SingleBlazeBlock(x, 48) ## bx32x32x48\n",
        "\n",
        "  x16 = DoubleBlazeBlock(x, 24, 96, strides = 2) ## bx16x16x96\n",
        "  _x = DoubleBlazeBlock(x16, 24, 96) ## bx16x16x96\n",
        "  _x = DoubleBlazeBlock(_x, 24, 96) ## bx16x16x96\n",
        "  _x = DoubleBlazeBlock(_x, 24, 96, strides = 2) ## bx8x8x96\n",
        "  _x = DoubleBlazeBlock(_x, 24, 96) ## bx8x8x96\n",
        "  x8 = DoubleBlazeBlock(_x, 24, 96) ## bx8x8x96\n",
        "\n",
        "  ####confidence\n",
        "  x16_conf = tf.keras.layers.Conv2D(kernel_size = 3, filters = 2, strides = 1, padding = 'same', activation = 'sigmoid')(x16) ## bx16x16x2\n",
        "  x8_conf = tf.keras.layers.Conv2D(kernel_size = 3, filters = 6, strides = 1, padding = 'same', activation = 'sigmoid')(x8) ## bx8x8x6\n",
        "\n",
        "  x_conf = tf.keras.layers.concatenate([tf.keras.layers.Reshape((512, 1))(x16_conf),tf.keras.layers.Reshape((384, 1))(x8_conf)],axis=1) ## bx896x1\n",
        "\n",
        "  ###bounding boxes\n",
        "  x16_bboxes = tf.keras.layers.Conv2D(kernel_size = 3, filters = 8, strides = 1, padding = 'same')(x16) ## bx16x16x8\n",
        "  x8_bboxes = tf.keras.layers.Conv2D(kernel_size = 3, filters = 24, strides = 1, padding = 'same')(x8) ## bx8x8x24\n",
        "\n",
        "  x_bboxes = tf.keras.layers.concatenate([tf.keras.layers.Reshape((512, 4))(x16_conf),tf.keras.layers.Reshape((384, 4))(x8_conf)],axis=1) ## bx896x4\n",
        "\n",
        "  #### Finally return both score and bounding boxes\n",
        "\n",
        "\n",
        "  return tf.keras.models.Model(inputs = inputs, outputs = [x_conf, x_bboxes])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AnSIwr9JWNs4",
        "colab_type": "code",
        "outputId": "feefc013-f718-4312-c0b6-748800242553",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model = network()\n",
        "print(model.summary())"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 128, 128, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 64, 64, 24)   1824        input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_3 (SeparableCo (None, 64, 64, 24)   1176        conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 64, 64, 24)   96          separable_conv2d_3[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 64, 64, 24)   0           batch_normalization_3[0][0]      \n",
            "                                                                 conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 64, 64, 24)   0           add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_4 (SeparableCo (None, 64, 64, 24)   1176        activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 64, 64, 24)   96          separable_conv2d_4[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 64, 64, 24)   0           batch_normalization_4[0][0]      \n",
            "                                                                 activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 64, 64, 24)   0           add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 32, 32, 24)   0           activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_5 (SeparableCo (None, 32, 32, 48)   1752        activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_ZerosLike (TensorFl [(None, 32, 32, 24)] 0           max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 32, 32, 48)   192         separable_conv2d_5[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_concat (TensorFlowO [(None, 32, 32, 48)] 0           max_pooling2d_1[0][0]            \n",
            "                                                                 tf_op_layer_ZerosLike[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, 32, 32, 48)   0           batch_normalization_5[0][0]      \n",
            "                                                                 tf_op_layer_concat[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 32, 32, 48)   0           add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_6 (SeparableCo (None, 32, 32, 48)   3504        activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 32, 32, 48)   192         separable_conv2d_6[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, 32, 32, 48)   0           batch_normalization_6[0][0]      \n",
            "                                                                 activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 32, 32, 48)   0           add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_7 (SeparableCo (None, 32, 32, 48)   3504        activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 32, 32, 48)   192         separable_conv2d_7[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "add_6 (Add)                     (None, 32, 32, 48)   0           batch_normalization_7[0][0]      \n",
            "                                                                 activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 32, 32, 48)   0           add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_8 (SeparableCo (None, 16, 16, 24)   2352        activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 16, 16, 24)   96          separable_conv2d_8[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 16, 16, 24)   0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 16, 16, 48)   0           activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_9 (SeparableCo (None, 16, 16, 96)   2904        activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_ZerosLike_1 (Tensor [(None, 16, 16, 48)] 0           max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 16, 16, 96)   384         separable_conv2d_9[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_concat_1 (TensorFlo [(None, 16, 16, 96)] 0           max_pooling2d_2[0][0]            \n",
            "                                                                 tf_op_layer_ZerosLike_1[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "add_7 (Add)                     (None, 16, 16, 96)   0           batch_normalization_9[0][0]      \n",
            "                                                                 tf_op_layer_concat_1[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 16, 16, 96)   0           add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_10 (SeparableC (None, 16, 16, 24)   4704        activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 16, 16, 24)   96          separable_conv2d_10[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 16, 16, 24)   0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_11 (SeparableC (None, 16, 16, 96)   2904        activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 16, 16, 96)   384         separable_conv2d_11[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "add_8 (Add)                     (None, 16, 16, 96)   0           batch_normalization_11[0][0]     \n",
            "                                                                 activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 16, 16, 96)   0           add_8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_12 (SeparableC (None, 16, 16, 24)   4704        activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 16, 16, 24)   96          separable_conv2d_12[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 16, 16, 24)   0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_13 (SeparableC (None, 16, 16, 96)   2904        activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 16, 16, 96)   384         separable_conv2d_13[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "add_9 (Add)                     (None, 16, 16, 96)   0           batch_normalization_13[0][0]     \n",
            "                                                                 activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 16, 16, 96)   0           add_9[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_14 (SeparableC (None, 8, 8, 24)     4704        activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 8, 8, 24)     96          separable_conv2d_14[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 8, 8, 24)     0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_15 (SeparableC (None, 8, 8, 96)     2904        activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 8, 8, 96)     384         separable_conv2d_15[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2D)  (None, 8, 8, 96)     0           activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_10 (Add)                    (None, 8, 8, 96)     0           batch_normalization_15[0][0]     \n",
            "                                                                 max_pooling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 8, 8, 96)     0           add_10[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_16 (SeparableC (None, 8, 8, 24)     4704        activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 8, 8, 24)     96          separable_conv2d_16[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 8, 8, 24)     0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_17 (SeparableC (None, 8, 8, 96)     2904        activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 8, 8, 96)     384         separable_conv2d_17[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "add_11 (Add)                    (None, 8, 8, 96)     0           batch_normalization_17[0][0]     \n",
            "                                                                 activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 8, 8, 96)     0           add_11[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_18 (SeparableC (None, 8, 8, 24)     4704        activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 8, 8, 24)     96          separable_conv2d_18[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 8, 8, 24)     0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_19 (SeparableC (None, 8, 8, 96)     2904        activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 8, 8, 96)     384         separable_conv2d_19[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "add_12 (Add)                    (None, 8, 8, 96)     0           batch_normalization_19[0][0]     \n",
            "                                                                 activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 8, 8, 96)     0           add_12[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 16, 16, 2)    1730        activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 8, 8, 6)      5190        activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "reshape (Reshape)               (None, 512, 1)       0           conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "reshape_1 (Reshape)             (None, 384, 1)       0           conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "reshape_2 (Reshape)             (None, 512, 4)       0           conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "reshape_3 (Reshape)             (None, 384, 4)       0           conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 896, 1)       0           reshape[0][0]                    \n",
            "                                                                 reshape_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 896, 4)       0           reshape_2[0][0]                  \n",
            "                                                                 reshape_3[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 66,800\n",
            "Trainable params: 64,976\n",
            "Non-trainable params: 1,824\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s-wFQRWOGYG2",
        "colab_type": "text"
      },
      "source": [
        "#Calculate IoU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vJK56UDoN_Pv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_intersection(bboxA, bboxB):\n",
        "  '''\n",
        "  bboxA:[A,4]\n",
        "  bboxB:[B,4]\n",
        "  \n",
        "  returns intersection of the boxes A and B of shape [A,B]\n",
        "  '''\n",
        "  numboxes_A = bboxA.shape[0]\n",
        "  numboxes_B = bboxB.shape[0]\n",
        "  max_xy = tf.math.minimum(tf.tile(tf.expand_dims(bboxA[:,2:],axis=1), multiples = (1,numboxes_B,1)),tf.tile(tf.expand_dims(bboxB[:,2:],axis=0), multiples = (numboxes_A,1,1)))\n",
        "  min_xy = tf.math.maximum(tf.tile(tf.expand_dims(bboxA[:,:2],axis=1), multiples = (1,numboxes_B,1)),tf.tile(tf.expand_dims(bboxB[:,:2],axis=0), multiples = (numboxes_A,1,1)))\n",
        "  intersections = tf.clip_by_value((max_xy - min_xy),clip_value_min = 0, clip_value_max = 16384)\n",
        "  return intersections[:,:,0]*intersections[:,:,1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yuA28VO3OJBm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_IoU(bboxA, bboxB):\n",
        "  '''\n",
        "  bboxA:[A,4]\n",
        "  bboxB:[B,4]\n",
        "  bbox_format: (xmin,ymin,xmax,ymax) \n",
        "\n",
        "  returns IoU of shape [A,B]\n",
        "  Note: If bbox is given in (x,y,w,h) format needs to be converted to (xmin,ymin,xmax,ymax)\n",
        "  '''\n",
        "  numboxes_A = bboxA.shape[0]\n",
        "  numboxes_B = bboxB.shape[0]\n",
        "  area_a = tf.tile(tf.expand_dims((bboxA[:,2]-bboxA[:,0])*(bboxA[:,3]-bboxA[:,1]), axis=1), multiples = (1,numboxes_B))\n",
        "  area_b = tf.tile(tf.expand_dims((bboxB[:,2]-bboxB[:,0])*(bboxB[:,3]-bboxB[:,1]), axis=0), multiples = (numboxes_A,1))\n",
        "  intersection = get_intersection(bboxA, bboxB)\n",
        "  union = area_a + area_b - intersection\n",
        "  return intersection/union"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4OxQsBZ8o8vy",
        "colab_type": "text"
      },
      "source": [
        "#Prediction Modules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EVeaoK9hBf54",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preds_to_coordinates(raw_box_preds, priors):\n",
        "  '''\n",
        "  raw_box_preds: (b, 896, 4)\n",
        "  priors: (896,4)\n",
        "\n",
        "  decodes raw predictions(offsets) from network to coordinates (xmin, ymin, xmax, ymax)\n",
        "  '''\n",
        "\n",
        "  bbox = tf.zeros_like(raw_box_preds)\n",
        "  xy_center = (raw_box_preds[:,:,:2] / 128) * priors[:,2:] + priors[:,:2] \n",
        "  wh = (raw_box_preds[:,:,2:] / 128) * priors[:,2:]\n",
        "  bbox[:,:,:2] = xy_center - wh/2 ####(xmin, ymin)\n",
        "  bbox[:,:,2:] = xy_center + wh/2 ####(xmax, ymax)\n",
        "  return bbox\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yGwE1yH0eoeq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_detections_from_preds(raw_box_preds, raw_score_preds, priors, clip_val = 100, conf_thresh = 0.6):\n",
        "  '''\n",
        "  raw_box_preds: (b, 896, 4)\n",
        "  priors: (896,4)\n",
        "  raw_score_preds: (b, 896, 1)\n",
        "  \n",
        "  returns detections of shape (b, num_detections, 5)\n",
        "\n",
        "  '''\n",
        "\n",
        "  raw_detection_boxes = preds_to_coordinates(raw_box_preds, priors)\n",
        "  raw_detection_score = tf.squeeze(raw_score_preds, axis=-1)\n",
        "  mask = raw_detection_score >= conf_thresh #### Discard boxes with too low confidence\n",
        "\n",
        "  filtered_output = []\n",
        "\n",
        "  for i in range(raw_box_preds.shape[0]):\n",
        "    boxes = raw_detection_boxes[i, mask[i]]\n",
        "    scores = raw_detection_score[i, mask[i]]\n",
        "    filtered_output.append(tf.concat([boxes, tf.expand_dims(scores,axis=-1)], axis=-1))\n",
        "\n",
        "  return filtered_output\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-urEyRfaO-Ge",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def weighted_nms(filtered_boxes, IoU_thresh = 0.5):\n",
        "  '''\n",
        "  filtered_boxes:(num_detections,5)\n",
        "  For each image with overlapping boxes with IoU above\n",
        "  a certain threshold it weighs the coordinates by the\n",
        "  normalized confidence score.\n",
        "  '''\n",
        "  detection_out = []\n",
        "\n",
        "  if (len(filtered_boxes) == 0):\n",
        "     return detection_out\n",
        "\n",
        "  sorted_ind = tf.argsort(filtered_boxes[:,-1], direction='DESCENDING')\n",
        "\n",
        "  while(len(sorted_ind)):\n",
        "    max_score_box = filtered_boxes[sorted_ind[0],:4]\n",
        "    remaining_boxes = tf.gather_nd(filtered_boxes[:,:4], tf.expand_dims(sorted_ind,axis=-1))\n",
        "    IoUs = get_IoU(max_score_box, remaining_boxes)\n",
        "    mask = IoUs > IoU_thresh\n",
        "\n",
        "    curr_overlaps = sorted_ind[mask]\n",
        "    sorted_ind = sorted_ind[~mask]\n",
        "    weighted_detection = max_score_box\n",
        "    if(curr_overlaps.shape[0] > 1):\n",
        "      score = tf.gather_nd(filtered_boxes[:,4], tf.expand_dims(curr_overlaps,axis=-1))\n",
        "      coordinates = tf.gather_nd(filtered_boxes[:,:4], tf.expand_dims(curr_overlaps,axis=-1))\n",
        "      normalized_score = score / tf.math.reduce_sum(score)\n",
        "      weighted_bbox = tf.math.reduce_sum(coordinates * normalized_score, axis = 0)\n",
        "      weighted_detection[:4] = weighted_bbox\n",
        "      weighted_detection[4] =  tf.math.reduce_sum(score) / curr_overlaps.shape[0]\n",
        "    \n",
        "    detection_out.append(weighted_detection)\n",
        "\n",
        "  \n",
        "  return detection_out\n",
        "\n",
        "\n",
        "\n",
        "  \n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7O1YHcPSW0_b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict(input, priors):\n",
        "  '''\n",
        "  input: tensor of shape (b,H,W,C)\n",
        "\n",
        "  returns prediction for the input of shape (b,num_detections,5)\n",
        "  \n",
        "  Note: If no face is detected in the image then a tensor of shape (0,5) is added for that image.\n",
        "  Also, priors can be saved once and for all of shape (896,4) of format (x,y,w,h)\n",
        "  '''\n",
        "\n",
        "  model = network()\n",
        "  out = model.predict(input)\n",
        "  raw_detections = get_detections_from_preds(out[0], out[1], priors)\n",
        "  \n",
        "  final_detections = []\n",
        "\n",
        "  for i in range(inputs.shape[0]):\n",
        "    faces = weighted_nms(raw_detections[i])\n",
        "    if(len(faces)>0):\n",
        "      faces = tf.stack(faces)\n",
        "    else:\n",
        "      faces = tf.zeros([0,5])\n",
        "    final_detections.append(faces)\n",
        "  return final_detections\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s13tYJNnpDRA",
        "colab_type": "text"
      },
      "source": [
        "#Training Modules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m4vcDRZ1vg10",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_offsets(matches, priors):\n",
        "  '''\n",
        "  matches:(num_priors,4), coordinate format:(xmin,ymin,xmax,ymax)\n",
        "  priors:(num_priors,4)\n",
        "\n",
        "  returns offsets of matches to priors of shape (num_priors,4) for regression\n",
        "  '''\n",
        "\n",
        "  ghat_cxcy = (matches[:,:2] + matches[:,2:])/(2 * 128) - priors[:,:2]\n",
        "  ghat_cxcy /= priors[:,2:]\n",
        "\n",
        "  ghat_wh = tf.log((matches[:,2:]-matches[:,:2])/(128*priors[:,2:]))\n",
        "\n",
        "  return tf.concat([ghat_cxcy, ghat_wh], axis=-1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ODGrU9UMR8Td",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def match(gt_box, gt_labels, priors, matched_loc_offset, matched_conf, idx, overlap_thresh = 0.5):\n",
        "  '''\n",
        "  gt_box:(num_objects, 4)\n",
        "  gt_labels:(num_objects)\n",
        "  matched_loc_offset:tensor of shape(b,num_priors,4) to be filled for batch index idx\n",
        "  matched_conf:tensor of shape(b,num_priors) to be filled for batch index idx\n",
        "\n",
        "  It matches each default box to a ground_truth box. \n",
        "  First assign each ground truth box a prior box with max IoU\n",
        "  and then assign each prior box a ground truth box with IoU greater than 0.5.\n",
        "  \n",
        "  '''\n",
        "\n",
        "  overlaps = get_IoU(gt_box, priors)\n",
        "  \n",
        "  #### assigns each gt_box a prior_box with max IoU\n",
        "  best_prior_overlap = tf.math.reduce_max(overlaps, axis = 1)\n",
        "  best_prior_idx = tf.math.argmax(overlaps, axis = 1)\n",
        "\n",
        "  #### assigns each prior_box a gt_box with max IoU\n",
        "  best_truth_overlap = tf.math.reduce_max(overlaps, axis = 0)\n",
        "  best_truth_idx = tf.math.argmax(overlaps, axis = 0)\n",
        "\n",
        "  #### ensure best match isn't missed due to thresholding\n",
        "  fill_value = tf.cast(tf.fill(best_prior_idx.shape[0], 3),dtype = best_truth_overlap.dtype)\n",
        "  best_truth_overlap = tf.tensor_scatter_nd_update(best_truth_overlap, tf.expand_dims(best_prior_idx, axis=1), fill_value)\n",
        "\n",
        "  for i in range(best_prior_idx.shape[0]):\n",
        "    best_truth_idx[best_prior_idx[i]] = i\n",
        "  \n",
        "  matches = tf.gather_nd(gt_box, tf.expand_dims(best_truth_idx, axis=1))\n",
        "  labels = tf.gather_nd(gt_labels, tf.expand_dims(best_truth_idx, axis=1)) + 1\n",
        "\n",
        "  bg_mask =  best_truth_overlap < overlap_thresh #### priors with IoU < threshold are background\n",
        "  labels[bg_mask] = 0 ### background class is 0\n",
        "\n",
        "  matched_loc_offset[idx] = get_offsets(matches, priors)\n",
        "  matched_conf[idx] = labels\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v4ZgjXHpnnXo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def weighted_loss(ground_truth, predictions):\n",
        "  '''\n",
        "  ground_truth:(b,num_obj,5)\n",
        "  predictions:[(b,num_priors,4),(b,num_priors,1)]\n",
        "\n",
        "  Note that we can save priors beforehand\n",
        "  returns a scalar smooth_l1_loss\n",
        "\n",
        "  Note: priors can be saved once and for all of shape (896,4) of format (x,y,w,h)\n",
        "  '''\n",
        "  priors = tf.convert_to_tensor(np.load(priors.npy), dtype = tf.float32)\n",
        "  pred_offset, pred_conf = predictions\n",
        "  batch_size = ground_truth.shape[0]\n",
        "  num_priors = priors.shape[0]\n",
        "  matched_loc_offset = tf.zeros_like(pred_offsets)\n",
        "  matched_conf = tf.zeros([batch_size, num_priors])\n",
        "\n",
        "  for idx in range(batch_size):\n",
        "    match(ground_truth[idx, :, :-1], ground_truth[idx, :, -1], priors, matched_loc_offset, matched_conf, idx)\n",
        "  \n",
        "\n",
        "  matched_loc_offset = tf.Variable(matched_loc_offset, trainable=False)\n",
        "  matched_conf = tf.Variable(matched_conf, trainable=False)\n",
        "\n",
        "  pos_class = matched_conf > 0\n",
        "  num_pos = tf.math.reduce_sum(pos_class, axis=1) ###(b,)\n",
        "\n",
        "  pred_offset = pred_offset[pos_class]\n",
        "  matched_loc_offset = matched_loc_offset[pos_class]\n",
        "\n",
        "\n",
        "  ##### Smooth L1 loss(localisation loss)\n",
        "  h = tf.keras.losses.Huber() ##### returns averaged loss\n",
        "  N = tf.math.reduce_sum(num_pos)\n",
        "  loc_loss = (h(matched_loc_offset, pred_offset) * (batch_size * num_priors * 4))\n",
        "\n",
        "  ####TODO: Hard Negative Mining \n",
        "\n",
        "  ##### Confidence Loss\n",
        "  bce = tf.keras.losses.BinaryCrossentropy()\n",
        "  conf_loss = bce(matched_conf, pred_conf) * (batch_size * num_priors)\n",
        "\n",
        "  averaged_loss = (loc_loss + conf_loss)/N\n",
        "\n",
        "  return averaged_loss \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  \n",
        "\n",
        "  \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OcMaEoaZoGPU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}