{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BlazeFace_.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO5eT3kqBYi7EQXxtoje/xl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/subham913/BlazeFace_/blob/master/BlazeFace_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2YX-vzctN24k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NKuUaRJNUuKu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def SingleBlazeBlock(x, filter_size, kernel_size = 5, strides = 1):\n",
        "  _x = tf.keras.layers.SeparableConv2D(filters = filter_size, kernel_size=kernel_size, strides = strides, padding = 'same', use_bias=False)(x)\n",
        "  _x = tf.keras.layers.BatchNormalization()(_x)\n",
        "  channel_pad = _x.shape[-1] - x.shape[-1] #######Channel padding for residual connections\n",
        "  if(strides==2):\n",
        "    x = tf.keras.layers.MaxPooling2D()(x)\n",
        "    if(channel_pad):\n",
        "      # x = tf.keras.backend.concatenate([x,tf.zeros((x.shape[0],x.shape[1],x.shape[2],channel_pad),dtype = x.dtype)],axis=-1)\n",
        "      x = tf.keras.backend.concatenate([x,tf.zeros_like(x)],axis=-1) \n",
        "  \n",
        "  x_out = tf.keras.layers.Add()([_x,x])\n",
        "  x_out = tf.keras.layers.Activation(\"relu\")(x_out)\n",
        "  return x_out\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W981b3JigMGe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def DoubleBlazeBlock(x, filter1_size, filter2_size, kernel_size = 5, strides = 1):\n",
        "  \n",
        "  _x1 = tf.keras.layers.SeparableConv2D(filters = filter1_size, kernel_size=kernel_size, strides= strides, padding = 'same', use_bias=False)(x)\n",
        "  _x1 = tf.keras.layers.BatchNormalization()(_x1)\n",
        "  _x1 = tf.keras.layers.Activation(\"relu\")(_x1)\n",
        "\n",
        "  _x2 = tf.keras.layers.SeparableConv2D(filters = filter2_size, kernel_size=kernel_size, strides = 1, padding = 'same', use_bias=False)(_x1)\n",
        "  _x2 = tf.keras.layers.BatchNormalization()(_x2)\n",
        "\n",
        "  channel_pad = _x2.shape[-1] - x.shape[-1]\n",
        "  if(strides==2):\n",
        "    x = tf.keras.layers.MaxPooling2D()(x)\n",
        "    if(channel_pad):\n",
        "      # x = tf.keras.backend.concatenate([x,tf.zeros((x.shape[0],x.shape[1],x.shape[2],channel_pad),dtype = x.dtype)],axis=-1)\n",
        "      x = tf.keras.backend.concatenate([x,tf.zeros_like(x)],axis=-1)\n",
        "  x_out = tf.keras.layers.Add()([_x2,x])\n",
        "  x_out = tf.keras.layers.Activation(\"relu\")(x_out)\n",
        "  return x_out\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SMROBVweSFRo",
        "colab_type": "text"
      },
      "source": [
        "#Test SigleBlazeBlock"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wHvC9fJERTFF",
        "colab_type": "code",
        "outputId": "a9853e9d-8171-466d-8701-66d942ee42fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import numpy as np\n",
        "# m  = tf.keras.layers.SeparableConv2D(filters = 24, kernel_size=5, strides = 2, padding = 'same')\n",
        "a = tf.convert_to_tensor(np.random.randn(3,64,64,24),dtype = tf.float32)\n",
        "out = SingleBlazeBlock(a, 48, strides=2)\n",
        "print(out.shape)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3, 32, 32, 48)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i4s97K4ASNDq",
        "colab_type": "text"
      },
      "source": [
        "# Test DoubleBlazeBlock"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e0GIq8lkSU7q",
        "colab_type": "code",
        "outputId": "305a1d82-0d18-4c10-dddc-0c0ba8edb26e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import numpy as np\n",
        "# m  = tf.keras.layers.SeparableConv2D(filters = 24, kernel_size=5, strides = 2, padding = 'same')\n",
        "a = tf.convert_to_tensor(np.random.randn(3,32,32,48),dtype = tf.float32)\n",
        "out = DoubleBlazeBlock(a, 24, 48, strides=1)\n",
        "print(out.shape)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3, 32, 32, 48)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9lbj21D6GTUS",
        "colab_type": "text"
      },
      "source": [
        "#Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AypFHCWRdJvt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def network():\n",
        "  inputs = tf.keras.layers.Input(shape=(128,128,3))\n",
        "  x = tf.keras.layers.Conv2D(kernel_size = 5, filters = 24, strides = 2, padding = 'same')(inputs) ## bx64x64x24\n",
        "  \n",
        "  x = SingleBlazeBlock(x, 24) ## bx64x64x24\n",
        "  x = SingleBlazeBlock(x, 24) ## bx64x64x24\n",
        "  x = SingleBlazeBlock(x, 48, strides = 2) ## bx32x32x48\n",
        "  x = SingleBlazeBlock(x, 48) ## bx32x32x48\n",
        "  x = SingleBlazeBlock(x, 48) ## bx32x32x48\n",
        "\n",
        "  x16 = DoubleBlazeBlock(x, 24, 96, strides = 2) ## bx16x16x96\n",
        "  _x = DoubleBlazeBlock(x16, 24, 96) ## bx16x16x96\n",
        "  _x = DoubleBlazeBlock(_x, 24, 96) ## bx16x16x96\n",
        "  _x = DoubleBlazeBlock(_x, 24, 96, strides = 2) ## bx8x8x96\n",
        "  _x = DoubleBlazeBlock(_x, 24, 96) ## bx8x8x96\n",
        "  x8 = DoubleBlazeBlock(_x, 24, 96) ## bx8x8x96\n",
        "\n",
        "  ####confidence\n",
        "  x16_conf = tf.keras.layers.Conv2D(kernel_size = 3, filters = 2, strides = 1, padding = 'same')(x16) ## bx16x16x2\n",
        "  x8_conf = tf.keras.layers.Conv2D(kernel_size = 3, filters = 6, strides = 1, padding = 'same')(x8) ## bx8x8x6\n",
        "\n",
        "  x_conf = tf.keras.layers.concatenate([tf.keras.layers.Reshape((512, 1))(x16_conf),tf.keras.layers.Reshape((384, 1))(x8_conf)],axis=1) ## bx896x1\n",
        "\n",
        "  ###bounding boxes\n",
        "  x16_bboxes = tf.keras.layers.Conv2D(kernel_size = 3, filters = 8, strides = 1, padding = 'same')(x16) ## bx16x16x8\n",
        "  x8_bboxes = tf.keras.layers.Conv2D(kernel_size = 3, filters = 24, strides = 1, padding = 'same')(x8) ## bx8x8x24\n",
        "\n",
        "  x_bboxes = tf.keras.layers.concatenate([tf.keras.layers.Reshape((512, 4))(x16_conf),tf.keras.layers.Reshape((384, 4))(x8_conf)],axis=1) ## bx896x4\n",
        "\n",
        "  #### Finally return both score and bounding boxes\n",
        "\n",
        "\n",
        "  return tf.keras.models.Model(inputs = inputs, outputs = [x_conf, x_bboxes])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AnSIwr9JWNs4",
        "colab_type": "code",
        "outputId": "62df4627-17ac-4580-85cd-75793054a221",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model = network()\n",
        "print(model.summary())"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            [(None, 128, 128, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 64, 64, 24)   1824        input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_20 (SeparableC (None, 64, 64, 24)   1176        conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 64, 64, 24)   96          separable_conv2d_20[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "add_13 (Add)                    (None, 64, 64, 24)   0           batch_normalization_20[0][0]     \n",
            "                                                                 conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 64, 64, 24)   0           add_13[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_21 (SeparableC (None, 64, 64, 24)   1176        activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 64, 64, 24)   96          separable_conv2d_21[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "add_14 (Add)                    (None, 64, 64, 24)   0           batch_normalization_21[0][0]     \n",
            "                                                                 activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 64, 64, 24)   0           add_14[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2D)  (None, 32, 32, 24)   0           activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_22 (SeparableC (None, 32, 32, 48)   1752        activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_ZerosLike_2 (Tensor [(None, 32, 32, 24)] 0           max_pooling2d_4[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 32, 32, 48)   192         separable_conv2d_22[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_concat_2 (TensorFlo [(None, 32, 32, 48)] 0           max_pooling2d_4[0][0]            \n",
            "                                                                 tf_op_layer_ZerosLike_2[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "add_15 (Add)                    (None, 32, 32, 48)   0           batch_normalization_22[0][0]     \n",
            "                                                                 tf_op_layer_concat_2[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 32, 32, 48)   0           add_15[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_23 (SeparableC (None, 32, 32, 48)   3504        activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 32, 32, 48)   192         separable_conv2d_23[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "add_16 (Add)                    (None, 32, 32, 48)   0           batch_normalization_23[0][0]     \n",
            "                                                                 activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 32, 32, 48)   0           add_16[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_24 (SeparableC (None, 32, 32, 48)   3504        activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, 32, 32, 48)   192         separable_conv2d_24[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "add_17 (Add)                    (None, 32, 32, 48)   0           batch_normalization_24[0][0]     \n",
            "                                                                 activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 32, 32, 48)   0           add_17[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_25 (SeparableC (None, 16, 16, 24)   2352        activation_24[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, 16, 16, 24)   96          separable_conv2d_25[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 16, 16, 24)   0           batch_normalization_25[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2D)  (None, 16, 16, 48)   0           activation_24[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_26 (SeparableC (None, 16, 16, 96)   2904        activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_ZerosLike_3 (Tensor [(None, 16, 16, 48)] 0           max_pooling2d_5[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_26 (BatchNo (None, 16, 16, 96)   384         separable_conv2d_26[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_concat_3 (TensorFlo [(None, 16, 16, 96)] 0           max_pooling2d_5[0][0]            \n",
            "                                                                 tf_op_layer_ZerosLike_3[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "add_18 (Add)                    (None, 16, 16, 96)   0           batch_normalization_26[0][0]     \n",
            "                                                                 tf_op_layer_concat_3[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 16, 16, 96)   0           add_18[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_27 (SeparableC (None, 16, 16, 24)   4704        activation_26[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_27 (BatchNo (None, 16, 16, 24)   96          separable_conv2d_27[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 16, 16, 24)   0           batch_normalization_27[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_28 (SeparableC (None, 16, 16, 96)   2904        activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_28 (BatchNo (None, 16, 16, 96)   384         separable_conv2d_28[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "add_19 (Add)                    (None, 16, 16, 96)   0           batch_normalization_28[0][0]     \n",
            "                                                                 activation_26[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 16, 16, 96)   0           add_19[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_29 (SeparableC (None, 16, 16, 24)   4704        activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_29 (BatchNo (None, 16, 16, 24)   96          separable_conv2d_29[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 16, 16, 24)   0           batch_normalization_29[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_30 (SeparableC (None, 16, 16, 96)   2904        activation_29[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_30 (BatchNo (None, 16, 16, 96)   384         separable_conv2d_30[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "add_20 (Add)                    (None, 16, 16, 96)   0           batch_normalization_30[0][0]     \n",
            "                                                                 activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 16, 16, 96)   0           add_20[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_31 (SeparableC (None, 8, 8, 24)     4704        activation_30[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_31 (BatchNo (None, 8, 8, 24)     96          separable_conv2d_31[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 8, 8, 24)     0           batch_normalization_31[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_32 (SeparableC (None, 8, 8, 96)     2904        activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_32 (BatchNo (None, 8, 8, 96)     384         separable_conv2d_32[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2D)  (None, 8, 8, 96)     0           activation_30[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_21 (Add)                    (None, 8, 8, 96)     0           batch_normalization_32[0][0]     \n",
            "                                                                 max_pooling2d_6[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 8, 8, 96)     0           add_21[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_33 (SeparableC (None, 8, 8, 24)     4704        activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_33 (BatchNo (None, 8, 8, 24)     96          separable_conv2d_33[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 8, 8, 24)     0           batch_normalization_33[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_34 (SeparableC (None, 8, 8, 96)     2904        activation_33[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_34 (BatchNo (None, 8, 8, 96)     384         separable_conv2d_34[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "add_22 (Add)                    (None, 8, 8, 96)     0           batch_normalization_34[0][0]     \n",
            "                                                                 activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 8, 8, 96)     0           add_22[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_35 (SeparableC (None, 8, 8, 24)     4704        activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_35 (BatchNo (None, 8, 8, 24)     96          separable_conv2d_35[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 8, 8, 24)     0           batch_normalization_35[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_36 (SeparableC (None, 8, 8, 96)     2904        activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_36 (BatchNo (None, 8, 8, 96)     384         separable_conv2d_36[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "add_23 (Add)                    (None, 8, 8, 96)     0           batch_normalization_36[0][0]     \n",
            "                                                                 activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 8, 8, 96)     0           add_23[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 16, 16, 2)    1730        activation_26[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 8, 8, 6)      5190        activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "reshape_4 (Reshape)             (None, 512, 1)       0           conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "reshape_5 (Reshape)             (None, 384, 1)       0           conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "reshape_6 (Reshape)             (None, 512, 4)       0           conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "reshape_7 (Reshape)             (None, 384, 4)       0           conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 896, 1)       0           reshape_4[0][0]                  \n",
            "                                                                 reshape_5[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, 896, 4)       0           reshape_6[0][0]                  \n",
            "                                                                 reshape_7[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 66,800\n",
            "Trainable params: 64,976\n",
            "Non-trainable params: 1,824\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s-wFQRWOGYG2",
        "colab_type": "text"
      },
      "source": [
        "#Calculate IoU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vJK56UDoN_Pv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_intersection(bboxA, bboxB):\n",
        "  '''\n",
        "  bboxA:[A,4]\n",
        "  bboxB:[B,4]\n",
        "  \n",
        "  returns intersection of the boxes A and B of shape [A,B]\n",
        "  '''\n",
        "  numboxes_A = bboxA.shape[0]\n",
        "  numboxes_B = bboxB.shape[0]\n",
        "  max_xy = tf.math.minimum(tf.tile(tf.expand_dims(bboxA[:,2:],axis=1), multiples = (1,numboxes_B,1)),tf.tile(tf.expand_dims(bboxB[:,2:],axis=0), multiples = (numboxes_A,1,1)))\n",
        "  min_xy = tf.math.maximum(tf.tile(tf.expand_dims(bboxA[:,:2],axis=1), multiples = (1,numboxes_B,1)),tf.tile(tf.expand_dims(bboxB[:,:2],axis=0), multiples = (numboxes_A,1,1)))\n",
        "  intersections = tf.clip_by_value((max_xy - min_xy),clip_value_min = 0, clip_value_max = 16384)\n",
        "  return intersections[:,:,0]*intersections[:,:,1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yuA28VO3OJBm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_IoU(bboxA, bboxB):\n",
        "  '''\n",
        "  bboxA:[A,4]\n",
        "  bboxB:[B,4]\n",
        "  bbox_format: (xmin,ymin,xmax,ymax) \n",
        "\n",
        "  returns IoU of shape [A,B]\n",
        "  Note: If bbox is given in (x,y,w,h) format needs to be converted to (xmin,ymin,xmax,ymax)\n",
        "  '''\n",
        "  numboxes_A = bboxA.shape[0]\n",
        "  numboxes_B = bboxB.shape[0]\n",
        "  area_a = tf.tile(tf.expand_dims((bboxA[:,2]-bboxA[:,0])*(bboxA[:,3]-bboxA[:,1]), axis=1), multiples = (1,numboxes_B))\n",
        "  area_b = tf.tile(tf.expand_dims((bboxB[:,2]-bboxB[:,0])*(bboxB[:,3]-bboxB[:,1]), axis=0), multiples = (numboxes_A,1))\n",
        "  intersection = get_intersection(bboxA, bboxB)\n",
        "  union = area_a + area_b - intersection\n",
        "  return intersection/union"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4OxQsBZ8o8vy",
        "colab_type": "text"
      },
      "source": [
        "#Prediction Modules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EVeaoK9hBf54",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preds_to_coordinates(raw_box_preds, priors):\n",
        "  '''\n",
        "  raw_box_preds: (b, 896, 4)\n",
        "  priors: (896,4)\n",
        "  decodes raw predictions from network to coordinates (xmin, ymin, xmax, ymax)\n",
        "  '''\n",
        "\n",
        "  bbox = tf.zeros_like(raw_box_preds)\n",
        "  xy_center = (raw_box_preds[:,:,:2] / 128) * priors[:,2:] + priors[:,:2] \n",
        "  wh = (raw_box_preds[:,:,2:] / 128) * priors[:,2:]\n",
        "  bbox[:,:,:2] = xy_center - wh/2 ####(xmin, ymin)\n",
        "  bbox[:,:,2:] = xy_center + wh/2 ####(xmax, ymax)\n",
        "  return bbox\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yGwE1yH0eoeq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_detections_from_preds(raw_box_preds, raw_score_preds, priors, clip_val = 100, conf_thresh = 0.6):\n",
        "  '''\n",
        "  raw_box_preds: (b, 896, 4)\n",
        "  priors: (896,4)\n",
        "  raw_score_preds: (b, 896, 1)\n",
        "  returns detections of shape (b, num_detections, 5)\n",
        "\n",
        "  '''\n",
        "\n",
        "  raw_detection_boxes = preds_to_coordinates(raw_box_preds, priors)\n",
        "  raw_detection_score = tf.sigmoid(tf.squeeze(tf.clip_by_value(raw_score_preds, clip_value_min = -clip_val, clip_value_max = clip_val),axis=-1))\n",
        "  mask = raw_detection_score >= conf_thresh #### Discard boxes with too low confidence\n",
        "\n",
        "  filtered_output = []\n",
        "\n",
        "  for i in range(raw_box_preds.shape[0]):\n",
        "    boxes = raw_detection_boxes[i, mask[i]]\n",
        "    scores = raw_detection_score[i, mask[i]]\n",
        "    filtered_output.append(tf.concat([boxes, tf.expand_dims(scores,axis=-1)], axis=-1))\n",
        "\n",
        "  return filtered_output\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-urEyRfaO-Ge",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def weighted_nms(filtered_boxes, IoU_thresh = 0.5):\n",
        "  '''\n",
        "  filtered_boxes:(num_detections,5)\n",
        "  For each image with overlapping boxes with IoU above\n",
        "  a certain threshold it weighs the coordinates by the\n",
        "  normalized confidence score.\n",
        "  '''\n",
        "  detection_out = []\n",
        "\n",
        "  if (len(filtered_boxes) == 0):\n",
        "     return detection_out\n",
        "\n",
        "  sorted_ind = tf.argsort(filtered_boxes[:,-1], direction='DESCENDING')\n",
        "\n",
        "  while(len(sorted_ind)):\n",
        "    max_score_box = filtered_boxes[sorted_ind[0],:4]\n",
        "    remaining_boxes = tf.gather_nd(filtered_boxes[:,:4], tf.expand_dims(sorted_ind,axis=-1))\n",
        "    IoUs = get_IoU(max_score_box, remaining_boxes)\n",
        "    mask = IoUs > IoU_thresh\n",
        "\n",
        "    curr_overlaps = sorted_ind[mask]\n",
        "    sorted_ind = sorted_ind[~mask]\n",
        "    weighted_detection = max_score_box\n",
        "    if(curr_overlaps.shape[0] > 1):\n",
        "      score = tf.gather_nd(filtered_boxes[:,4], tf.expand_dims(curr_overlaps,axis=-1))\n",
        "      coordinates = tf.gather_nd(filtered_boxes[:,:4], tf.expand_dims(curr_overlaps,axis=-1))\n",
        "      normalized_score = score / tf.math.reduce_sum(score)\n",
        "      weighted_bbox = tf.math.reduce_sum(coordinates * normalized_score, axis = 0)\n",
        "      weighted_detection[:4] = weighted_bbox\n",
        "      weighted_detection[4] =  tf.math.reduce_sum(score) / curr_overlaps.shape[0]\n",
        "    \n",
        "    detection_out.append(weighted_detection)\n",
        "\n",
        "  \n",
        "  return detection_out\n",
        "\n",
        "\n",
        "\n",
        "  \n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7O1YHcPSW0_b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict(input, priors):\n",
        "  '''\n",
        "  input: tensor of shape (b,H,W,C)\n",
        "\n",
        "  returns prediction for the input of shape (b,num_detections,5)\n",
        "  \n",
        "  Note: If no face is detected in the image then a tensor of shape (0,5) is added for that image.\n",
        "  Also, priors can be saved once and for all of shape (896,4) of format (x,y,w,h)\n",
        "  '''\n",
        "\n",
        "  model = network()\n",
        "  out = model.predict(input)\n",
        "  raw_detections = get_detections_from_preds(out[0], out[1], priors)\n",
        "  \n",
        "  final_detections = []\n",
        "\n",
        "  for i in range(inputs.shape[0]):\n",
        "    faces = weighted_nms(raw_detections[i])\n",
        "    if(len(faces)>0):\n",
        "      faces = tf.stack(faces)\n",
        "    else:\n",
        "      faces = tf.zeros([0,5])\n",
        "    final_detections.append(faces)\n",
        "  return final_detections\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s13tYJNnpDRA",
        "colab_type": "text"
      },
      "source": [
        "#Training Modules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m4vcDRZ1vg10",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_offsets(matches, priors):\n",
        "  '''\n",
        "  matches:(num_priors,4), coordinate format:(xmin,ymin,xmax,ymax)\n",
        "  priors:(num_priors,4)\n",
        "\n",
        "  returns offsets of matches to priors of shape (num_priors,4) for regression\n",
        "  '''\n",
        "\n",
        "  ghat_cxcy = (matches[:,:2] + matches[:,2:])/2 - priors[:,:2]\n",
        "  ghat_cxcy /= priors[:,2:]\n",
        "\n",
        "  ghat_wh = tf.log((matches[:,2:]-matches[:,:2])/priors[:,2:])\n",
        "\n",
        "  return tf.concat([ghat_cxcy, ghat_wh], axis=-1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ODGrU9UMR8Td",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def match(gt_box, gt_labels, priors, matched_loc_offset, matched_conf, idx, overlap_thresh = 0.5):\n",
        "  '''\n",
        "  gt_box:(num_objects, 4)\n",
        "  gt_labels:(num_objects)\n",
        "  matched_loc_offset:tensor of shape(b,num_priors,4) to be filled for batch index idx\n",
        "  matched_conf:tensor of shape(b,num_priors) to be filled for batch index idx\n",
        "\n",
        "  It matches each default box to a ground_truth box. \n",
        "  First assign each ground truth box a prior box with max IoU\n",
        "  and then assign each prior box a ground truth box with IoU greater than 0.5.\n",
        "  \n",
        "  '''\n",
        "\n",
        "  overlaps = get_IoU(gt_box, priors)\n",
        "  \n",
        "  #### assigns each gt_box a prior_box with max IoU\n",
        "  best_prior_overlap = tf.math.reduce_max(overlaps, axis = 1)\n",
        "  best_prior_idx = tf.math.argmax(overlaps, axis = 1)\n",
        "\n",
        "  #### assigns each prior_box a gt_box with max IoU\n",
        "  best_truth_overlap = tf.math.reduce_max(overlaps, axis = 0)\n",
        "  best_truth_idx = tf.math.argmax(overlaps, axis = 0)\n",
        "\n",
        "  #### ensure best match isn't missed due to thresholding\n",
        "  fill_value = tf.cast(tf.fill(best_prior_idx.shape[0], 3),dtype = best_truth_overlap.dtype)\n",
        "  best_truth_overlap = tf.tensor_scatter_nd_update(best_truth_overlap, tf.expand_dims(best_prior_idx, axis=1), fill_value)\n",
        "\n",
        "  for i in range(best_prior_idx.shape[0]):\n",
        "    best_truth_idx[best_prior_idx[i]] = i\n",
        "  \n",
        "  matches = tf.gather_nd(gt_box, tf.expand_dims(best_truth_idx, axis=1))\n",
        "  labels = tf.gather_nd(gt_labels, tf.expand_dims(best_truth_idx, axis=1)) + 1\n",
        "\n",
        "  bg_mask =  best_truth_overlap < overlap_thresh #### priors with IoU < threshold are background\n",
        "  labels[bg_mask] = 0 ### background class is 0\n",
        "\n",
        "  matched_loc_offset[idx] = get_offsets(matches, priors)\n",
        "  matched_conf[idx] = labels\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v4ZgjXHpnnXo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def weighted_loss(ground_truth, predictions):\n",
        "  '''\n",
        "  ground_truth:(b,num_obj,5)\n",
        "  predictions:[(b,num_priors,4),(b,num_priors,1)]\n",
        "\n",
        "  Note that we can save priors beforehand\n",
        "  returns a scalar smooth_l1_loss\n",
        "\n",
        "  Note: priors can be saved once and for all of shape (896,4) of format (x,y,w,h)\n",
        "  '''\n",
        "  priors = tf.convert_to_tensor(np.load(priors.npy), dtype = tf.float32)\n",
        "  pred_offset, pred_conf = predictions\n",
        "  batch_size = ground_truth.shape[0]\n",
        "  num_priors = priors.shape[0]\n",
        "  matched_loc_offset = tf.zeros_like(pred_offsets)\n",
        "  matched_conf = tf.zeros([batch_size, num_priors])\n",
        "\n",
        "  for idx in range(batch_size):\n",
        "    match(ground_truth[idx, :, :-1], ground_truth[idx, :, -1], priors, matched_loc_offset, matched_conf, idx)\n",
        "  \n",
        "\n",
        "  matched_loc_offset = tf.Variable(matched_loc_offset, trainable=False)\n",
        "  matched_conf = tf.Variable(matched_conf, trainable=False)\n",
        "\n",
        "  pos_class = matched_conf > 0\n",
        "  num_pos = tf.math.reduce_sum(pos_class, axis=1) ###(b,)\n",
        "\n",
        "  pred_offset = pred_offset[pos_class]\n",
        "  matched_loc_offset = matched_loc_offset[pos_class]\n",
        "\n",
        "\n",
        "  ##### Smooth L1 loss(localisation loss)\n",
        "  h = tf.keras.losses.Huber() ##### returns averaged loss\n",
        "  N = tf.math.reduce_sum(num_pos)\n",
        "  loc_loss = (h(matched_loc_offset, pred_offset) * (batch_size * num_priors * 4))\n",
        "\n",
        "  ####TODO: Hard Negative Mining \n",
        "\n",
        "  ##### Confidence Loss\n",
        "  bce = tf.keras.losses.BinaryCrossentropy()\n",
        "  conf_loss = bce(matched_conf, pred_conf) * (batch_size * num_priors)\n",
        "\n",
        "  averaged_loss = (loc_loss + conf_loss)/N\n",
        "\n",
        "  return averaged_loss \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  \n",
        "\n",
        "  \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OcMaEoaZoGPU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}